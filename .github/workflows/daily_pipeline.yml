name: Daily ELT Pipeline

# 1. WHEN to run:
on:
  schedule:
    - cron: '0 6 * * *'  # 6:00 AM UTC every day
  workflow_dispatch:      # Allows manual trigger

# 2. THE SETUP:
env:
  MOTHERDUCK_TOKEN: ${{ secrets.MOTHERDUCK_TOKEN }}
  GCP_ACCESS_KEY: ${{ secrets.GCP_ACCESS_KEY }}
  GCP_SECRET_KEY: ${{ secrets.GCP_SECRET_KEY }}

jobs:
  run_dbt_job:
    runs-on: ubuntu-latest

  
    # This tells the robot: "Do all work inside this specific subfolder"
    defaults:
      run:
        working-directory: ./elt_data_pipeline_version_1

    steps:
      # A. Download your code
      - name: Check out code
        uses: actions/checkout@v3

      # B. Install Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # C. Install dbt and DuckDB (Specific versions as requested)
      - name: Install dependencies
        run: |
          pip install dbt-duckdb>=1.8.1 duckdb==1.1.2

      # D. Run the Pipeline
      - name: Run dbt
        run: |
          dbt deps
          dbt run --profiles-dir .